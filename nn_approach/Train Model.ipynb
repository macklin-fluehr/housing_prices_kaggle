{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset.regressor_dataset import RegressorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "# import models.complementary_basemodel\n",
    "# from loss.nt_xent import NTXentLoss\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(data_aug.complement_dataset)\n",
    "# importlib.reload(models.complementary_basemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As nice as it is to have extra info, if the col is mostly null, I'm not interested\n",
    "df = df[[c for c in df.columns if pd.isnull(df[c]).sum() < df.shape[0] - 100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_subset = pd.Series(df.dtypes[df.dtypes == \"object\"].index).sample(3).tolist()\n",
    "df = df[df.dtypes[df.dtypes != \"object\"].index.tolist() + cat_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = df.dtypes[df.dtypes != \"object\"].index.tolist()\n",
    "cat_cols = df.dtypes[df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For continuous features, impute the mean\n",
    "for c in cont_cols:\n",
    "    df[c] = df[c].fillna(df[c].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling\n",
    "ss = StandardScaler()\n",
    "\n",
    "scaled = df.drop(cat_cols, axis=1)\n",
    "scaled = pd.DataFrame(ss.fit_transform(scaled), index=df.index, columns=scaled.columns)\n",
    "\n",
    "df = pd.concat([df[cat_cols], scaled], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna(-1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OrdinalEncoder()\n",
    "\n",
    "encoded = df.drop(cont_cols, axis=1)\n",
    "encoded = pd.DataFrame(oe.fit_transform(encoded), index=df.index, columns=encoded.columns)\n",
    "\n",
    "df = pd.concat([df[cont_cols], encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_col_info\n",
    "categorical_col_info = {cat_name: len(categories) for cat_name, categories in zip(cat_cols, oe.categories_)}\n",
    "\n",
    "categorical_feature_names = list(categorical_col_info.keys())\n",
    "\n",
    "embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) \n",
    "                   for _,n_categories in categorical_col_info.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_model_features = [\"Id\", \"SalePrice\"]\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.drop(non_model_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Datasets\n",
    "train_data = RegressorDataset(X_train, y_train, categorical_feature_names)\n",
    "test_data = RegressorDataset(X_test, y_test, categorical_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuous Features\n",
    "n_cont = X_train.drop(categorical_feature_names, axis=1).shape[1]\n",
    "n_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 10,\n",
    "    \"num_batches_per_epoch\": 200,\n",
    "    \"eval_every_n_epochs\": 1,\n",
    "    \"fine_tune_from\": \"None\",\n",
    "    \"log_every_n_steps\": 5,\n",
    "    \"model\": {\n",
    "        \"n_cont\": n_cont,\n",
    "        \"embedding_sizes\": embedding_sizes,\n",
    "        \"out_dim\": 1  # it's a regression problem\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=config[\"batch_size\"],\n",
    "                         shuffle=True)\n",
    "valid_loader = DataLoader(test_data, batch_size=config[\"batch_size\"],\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _save_config_file(model_checkpoints_folder):\n",
    "#     if not os.path.exists(model_checkpoints_folder):\n",
    "#         os.makedirs(model_checkpoints_folder)\n",
    "#         shutil.copy(\n",
    "#             \"./config.yaml\",\n",
    "#             os.path.join(model_checkpoints_folder, \"config.yaml\"),\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.embedding_basemodel import EmbeddingBaseModel\n",
    "# from complement import Complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = self._get_device()\n",
    "        self.writer = SummaryWriter()\n",
    "        self.loss = MSELoss()\n",
    "\n",
    "    def _get_device(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(\"Running on:\", device)\n",
    "        return device\n",
    "\n",
    "    def train(self, train_loader, valid_loader):\n",
    "\n",
    "        model = EmbeddingBaseModel(**self.config[\"model\"]).to(self.device)\n",
    "#         model = self._load_pre_trained_weights(model)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                    1e-4)\n",
    "\n",
    "#         model_checkpoints_folder = os.path.join(\n",
    "#             self.writer.log_dir, \"checkpoints\"\n",
    "#         )\n",
    "\n",
    "        # save config file\n",
    "#         _save_config_file(model_checkpoints_folder)\n",
    "\n",
    "        n_iter = 0\n",
    "        valid_n_iter = 0\n",
    "        best_valid_loss = np.inf\n",
    "\n",
    "        for epoch_counter in tqdm(range(self.config[\"epochs\"]), desc=\"epochs\"):\n",
    "            for data, label in tqdm(train_loader, desc=\"batches\"):\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss = self._step(model, data, label, n_iter)\n",
    "                \n",
    "                break\n",
    "\n",
    "                if n_iter % self.config[\"log_every_n_steps\"] == 0:\n",
    "                    print(\"Train Loss: {:.2f}\".format(loss))\n",
    "#                     self.writer.add_scalar(\n",
    "#                         \"train_loss\", loss, global_step=n_iter\n",
    "#                     )\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                n_iter += 1\n",
    "\n",
    "#                 if n_iter % self.config[\"num_batches_per_epoch\"] == 0:\n",
    "#                     break\n",
    "\n",
    "            # validate the model if requested\n",
    "            if epoch_counter % self.config[\"eval_every_n_epochs\"] == 0:\n",
    "                valid_loss = self._validate(model, valid_loader)\n",
    "                print(\"----VALID LOSS: \" + str(valid_loss) + \"----\")\n",
    "                if valid_loss < best_valid_loss:\n",
    "                    # save the model weights\n",
    "                    best_valid_loss = valid_loss\n",
    "#                     torch.save(\n",
    "#                         model.state_dict(),\n",
    "#                         os.path.join(model_checkpoints_folder, \"model.pth\"),\n",
    "#                     )\n",
    "\n",
    "#                 self.writer.add_scalar(\n",
    "#                     \"validation_loss\", valid_loss, global_step=valid_n_iter\n",
    "#                 )\n",
    "                valid_n_iter += 1\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def _load_pre_trained_weights(self, model):\n",
    "        try:\n",
    "            checkpoints_folder = os.path.join(\n",
    "                \"./runs\", self.config[\"fine_tune_from\"], \"checkpoints\"\n",
    "            )\n",
    "            state_dict = torch.load(\n",
    "                os.path.join(checkpoints_folder, \"model.pth\")\n",
    "            )\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(\"Loaded pre-trained model with success.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Pre-trained weights not found. Training from scratch.\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _step(self, model, data, label, n_iter):\n",
    "        \"\"\"\n",
    "        Calculate the loss on the batch\n",
    "        \"\"\"\n",
    "\n",
    "        cont = data[0].to(self.device)\n",
    "        cat = data[1].to(self.device)\n",
    "        label = label.to(self.device).float()\n",
    "\n",
    "        h1 = model(cont, cat)\n",
    "\n",
    "        loss = self.loss(h1, label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _validate(self, model, valid_loader):\n",
    "\n",
    "        # validation steps\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            valid_loss = 0.0\n",
    "            for counter, (data, label) in enumerate(valid_loader):\n",
    "\n",
    "                loss = self._step(model, data, label, counter)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "#                 if counter > 10:\n",
    "#                     break\n",
    "\n",
    "            valid_loss /= counter\n",
    "        model.train()\n",
    "        return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "model = Regressor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
      "epochs:  10%|█         | 1/10 [00:00<00:00,  9.17it/s]\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.304366992579566----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  20%|██        | 2/10 [00:00<00:00,  9.12it/s]\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.254638026158015----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.2679460810290442----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epochs:  40%|████      | 4/10 [00:00<00:00,  9.47it/s]\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
      "epochs:  60%|██████    | 6/10 [00:00<00:00,  9.83it/s]\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----VALID LOSS: 1.2605650623639424----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.281115483906534----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.360733648141225----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
      "epochs:  80%|████████  | 8/10 [00:00<00:00, 10.06it/s]\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.25862355530262----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.3419025672806635----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:   0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
      "epochs: 100%|██████████| 10/10 [00:00<00:00, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.2449223515060213----\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "2\n",
      "torch.Size([4, 36])\n",
      "torch.Size([4, 3])\n",
      "----VALID LOSS: 1.2662208527326584----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.train(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(RegressorDataset(X_test, None, categorical_feature_names),\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "model.eval()\n",
    "for cont, cat in test_loader:\n",
    "    predictions.extend(model(cont, cat).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a38678190>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predictions).hist(bins=20, alpha=0.3, density=True,\n",
    "                            label=\"model_label_distribution\")\n",
    "y_test.hist(bins=20, alpha=0.3, density=True,\n",
    "            label=\"true label distribution\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
